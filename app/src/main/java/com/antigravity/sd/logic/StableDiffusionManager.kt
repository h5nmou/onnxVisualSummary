package com.antigravity.sd.logic

import android.content.Context
import android.graphics.Bitmap
import android.graphics.Color
import android.util.Half
import android.util.Log
import ai.onnxruntime.OnnxJavaType
import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtLoggingLevel
import ai.onnxruntime.OrtSession
import ai.onnxruntime.providers.NNAPIFlags
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.flow
import kotlinx.coroutines.flow.flowOn
import kotlinx.coroutines.withContext
import java.nio.FloatBuffer
import java.nio.IntBuffer
import java.nio.LongBuffer
import java.util.Collections
import java.util.EnumSet
import kotlin.math.pow
import kotlin.math.roundToInt
import kotlin.math.sqrt

class StableDiffusionManager(private val context: Context) {

    private val env: OrtEnvironment = OrtEnvironment.getEnvironment()
    private var tokenizer = CLIPTokenizer()

    // Sessions
    private var textEncoderSession: OrtSession? = null
    private var unetSession: OrtSession? = null
    private var vaeDecoderSession: OrtSession? = null

    // Scheduler Config
    private val numInferenceSteps = 20
    private val betaStart = 0.00085f
    private val betaEnd = 0.012f
    private val betas = FloatArray(1000)
    private val alphas = FloatArray(1000)
    private val alphasCumprod = FloatArray(1000)
    private val sigmas = FloatArray(1000)
    
    init {
        // Initialize Scheduler Constants (Linear Beta Schedule)
        var alphaCumprodPrev = 1.0f
        for (i in 0 until 1000) {
            val beta = betaStart + (betaEnd - betaStart) * i / 999f
            betas[i] = beta
            alphas[i] = 1.0f - beta
            alphasCumprod[i] = alphas[i] * alphaCumprodPrev
            alphaCumprodPrev = alphasCumprod[i]
            sigmas[i] = sqrt((1 - alphasCumprod[i]) / alphasCumprod[i])
        }
    }

    // Track Active Device
    private var activeDevice = "CPU"

    // Track Active Device


    suspend fun initializeModels(onStatus: (String) -> Unit) = withContext(Dispatchers.IO) {
        try {
            onStatus("Installing Models...")
            Log.d("Antigravity-SD", "Installing Models...")

            val npuPropeties = OrtSession.SessionOptions()
            npuPropeties.setOptimizationLevel(OrtSession.SessionOptions.OptLevel.NO_OPT) // ğŸš¨ NO_OPT: Prevent 'Cast' insertion
            
            // ğŸš¨ STATIC SHAPES: Configuration Bypass (Attempt 2: Comma Separated)
            // Trying both standard key formats just in case.
            npuPropeties.addConfigEntry("free_dimension_overrides", "batch:1,channels:4,height:64,width:64,sequence:77")
            npuPropeties.addConfigEntry("session.free_dimension_overrides", "batch:1,channels:4,height:64,width:64,sequence:77")

            npuPropeties.addConfigEntry("session.disable_nhwc_conv_optimization", "0")
            npuPropeties.addConfigEntry("session.layout_optimization", "1")

            // ğŸš¨ [í•µì‹¬ 2] ë¡œê·¸ ì¼œê¸° (ì—ëŸ¬ í™•ì¸ìš©)
            npuPropeties.setSessionLogVerbosityLevel(0) 
            npuPropeties.setSessionLogLevel(OrtLoggingLevel.ORT_LOGGING_LEVEL_VERBOSE)
            npuPropeties.addConfigEntry("session.logid", "S25_Diagnostic")

            npuPropeties.setInterOpNumThreads(1)
            npuPropeties.setIntraOpNumThreads(1)

            Log.d("Antigravity-SD", "Attempting FORCE NPU Load (NO_OPT + CPU_DISABLED)...")
            try {
                // ğŸš¨ [í•µì‹¬ 3] CPU ì‚¬ìš© ê¸ˆì§€ (Zero-Fallback Mode)
                // Force NPU to be EXCLUSIVE. If any node fails, CRASH.
                val flags = EnumSet.of(NNAPIFlags.USE_FP16, NNAPIFlags.CPU_DISABLED)

                // Additional Hardcore Flags for S25
                npuPropeties.addConfigEntry("nnapi.relax_fp32_to_fp16", "1") 
                // Note: onnxruntime-android usually maps these via flags, but adding config entries for safety if supported by EP options parsing
                // Actually, for NNAPI EP in standard ORT, these are set via `NnapiExecutionProviderOptions` which is C-API. 
                // The Java `addNnapi` helper handles flags. `relax_fp32_to_fp16` corresponds to `USE_FP16` or internal settings.
                // The user requested `nnapiOptions = mapOf(...)`. The Java API for addNnapi doesn't expose a definition for arbitrary map easily in this version maybe?
                // Wait, `addNnapi(flags)` is standard.
                // Let's stick to the flags I *can* set in Java. `USE_FP16` is the main one.
                // But the user Prompt SPECIFICALLY asked for:
                // `nnapiOptions = mapOf("relax_fp32_to_fp16" to "1", "override_int8_to_fp16" to "1")`
                // I suspect the user might be referring to a different API or wants me to try adding these as global config entries?
                // ORT usually uses `provider_options` for EPs.
                // `session.nnapi.flags` etc.
                // I will add them as global config entries just in case properties propagate.
                npuPropeties.addConfigEntry("session.nnapi.relax_fp32_to_fp16", "1")
                
                npuPropeties.addNnapi(flags)
                activeDevice = "NPU_ONLY"
                Log.d("Antigravity-SD", "ğŸ”¥ NPU FORCE MODE: CPU fallback is strictly disabled.")
            } catch (e: Exception) {
                Log.e("Antigravity-SD", "CRITICAL NPU FAILURE", e)
                throw e
            }

            val cpuOptions = OrtSession.SessionOptions()
            cpuOptions.setOptimizationLevel(OrtSession.SessionOptions.OptLevel.ALL_OPT)
            cpuOptions.addConfigEntry("session.use_ort_model_bytes_directly", "1")
            cpuOptions.setInterOpNumThreads(1)
            cpuOptions.setIntraOpNumThreads(4)

            // 2. Smart Asset Search (Scan & Validate)
            var assetPrefix = "model/sd/" // Fallback
            val candidates = listOf("models/sd", "model/sd", "sd", "")
            var foundValidTextEncoder = false

            for (dir in candidates) {
                val currentPrefix = if (dir.isEmpty()) "" else "$dir/"
                val testAssetPath = currentPrefix + "text_encoder.onnx"

                // Check if asset exists
                val assetExists = try {
                    context.assets.list(dir)?.contains("text_encoder.onnx") == true
                } catch (e: Exception) { false }

                if (assetExists) {
                    Log.d("Antigravity-SD", "Checking candidate: '$testAssetPath'...")

                    // Copy to TEMP file for validation
                    val tempFile = java.io.File(context.filesDir, "temp_text_encoder_check.onnx")
                    try {
                        context.assets.open(testAssetPath).use { input ->
                            java.io.FileOutputStream(tempFile).use { output -> input.copyTo(output) }
                        }

                        // Validate Session
                        val session = env.createSession(tempFile.absolutePath, npuPropeties)
                        val inputs = session.inputNames
                        session.close()

                        if (inputs.contains("input_ids")) {
                            Log.d("Antigravity-SD", "VALID Match Found in '$dir'! Inputs: $inputs")
                            assetPrefix = currentPrefix

                            // Rename temp to real
                            val realFile = java.io.File(context.filesDir, "text_encoder.onnx")
                            if (realFile.exists()) realFile.delete()
                            tempFile.renameTo(realFile)

                            foundValidTextEncoder = true
                            break
                        } else {
                            Log.w("Antigravity-SD", "INVALID Candidate in '$dir'. Found inputs: $inputs. Skipping.")
                            tempFile.delete() // Cleanup bad file
                        }
                    } catch (e: Exception) {
                        Log.w("Antigravity-SD", "Error validating candidate '$dir': ${e.message}")
                        tempFile.delete()
                    }
                }
            }

            if (!foundValidTextEncoder) {
                val rootList = context.assets.list("")?.joinToString()
                Log.e("Antigravity-SD", "CRITICAL: No valid 'text_encoder.onnx' found! Root: [$rootList]")
                throw java.io.FileNotFoundException("Could not find a valid text_encoder.onnx in assets.")
            }

            // 3. Install Remaining Assets
            copyAssetToFile(assetPrefix + "vae_decoder.onnx")
            
            // Note: UNet is now loaded via getModelPath("unet_static_fp16.onnx") which handles copy on demand.
            // copyAssetToFile(assetPrefix + "unet_fp16.onnx") // REMOVED: Legacy
            // copyAssetToFile(assetPrefix + "weights.pb")      // REMOVED: Legacy

            onStatus("Loading Models...")
            Log.d("Antigravity-SD", "Loading Models from ${context.filesDir.absolutePath}...")

            val filesDir = context.filesDir

            // Text Encoder
            val textEncoderPath = java.io.File(filesDir, "text_encoder.onnx").absolutePath
            textEncoderSession = env.createSession(textEncoderPath, npuPropeties)

            // Text Encoder Validation
            val inputs = textEncoderSession!!.inputNames
            val outputs = textEncoderSession!!.outputNames

            if (!inputs.contains("input_ids")) {
                Log.e("Antigravity-SD", "CRITICAL MODEL ERROR: Text Encoder Invalid")
                Log.w("Antigravity-SD", "Attempting self-healing (Delete & Re-Copy)...")

                textEncoderSession!!.close()
                val corruptedFile = java.io.File(textEncoderPath)
                if (corruptedFile.exists()) corruptedFile.delete()

                copyAssetToFile(assetPrefix + "text_encoder.onnx", overwrite = true)

                textEncoderSession = env.createSession(textEncoderPath, npuPropeties)
                if (!textEncoderSession!!.inputNames.contains("input_ids")) {
                    throw RuntimeException("Text Encoder Invalid. Re-validation failed.")
                }
                Log.i("Antigravity-SD", "Self-healing successful.")
            }

            // UNet FP16 (NPU) - Static Shape
            // ğŸš¨ Use getModelPath to ensure both .onnx and .data are present
            val unetPath = getModelPath("unet_static_fp16.onnx")
            
            unetSession = env.createSession(unetPath, npuPropeties)
            
            // ğŸ” DEBUG: Log UNet Signature
            Log.d("Antigravity-SD", "UNet Model Signature:")
            unetSession!!.inputInfo.forEach { (name, info) ->
                Log.d("Antigravity-SD", " - Input: $name -> $info")
            }
            unetSession!!.outputInfo.forEach { (name, info) ->
                Log.d("Antigravity-SD", " - Output: $name -> $info")
            }

            // VAE Decoder (CPU)
            val vaePath = java.io.File(filesDir, "vae_decoder.onnx").absolutePath
            vaeDecoderSession = env.createSession(vaePath, cpuOptions)

            Log.i("Antigravity-SD", "SD Engine Ready. Device: $activeDevice")
            onStatus("Ready ($activeDevice)")

        } catch (e: Exception) {
            Log.e("Antigravity-SD", "Initialization failed", e)
            onStatus("Error: ${e.message}")
            throw e
        }
    }

    // ... [Helpers copyAllModelsFromAssets, getOrMergeWeights kept as is by diff context usually, but here I am targeting lines 57-138 mostly for init]
    // Wait, I need to verify I am not wiping helpers if I only target init.
    // The previous diff ended at line 138 (end of init).
    // I will replace generateImage (line 197+) separately or in same block if I can bridge it. 
    // It's safer to do 2 chunks or just target the functions individually.
    // I will target `initializeModels` first (S25 Threads).
    // Actually, I can combine if I use MultiReplace.
    // Let's stick to replacing `initializeModels` block (lines 57-138) and `generateImage` block (197-285).
    // But this tool call only allows single contiguous or I use multi_replace.
    // I will use `replace_file_content` for `initializeModels` now, then `generateImage`.
    
    // Ah, wait. I will do ONE BIG replacement for the whole logic part if feasible, or just iterate.
    // Let's do `initializeModels` optimization first.
    
    // NO, I will use `multi_replace_file_content` to do both at once.
    // ...
    // Actually, let's just do `initializeModels` modification first manually here.
    
    // Changing strategy: I will replace the whole file content for lines 99-102 (Threads) and 197-285 (Generate).
    // Let's use `multi_replace_file_content`.



    // Helper: Get Model Path (Copies .onnx AND .data from assets if needed)
    private fun getModelPath(fileName: String): String {
        val file = java.io.File(context.filesDir, fileName)
        val dataFile = java.io.File(context.filesDir, "$fileName.data")

        // Check if both files exist. If not, copy BOTH.
        // Note: ONNX Runtime needs the .data file to be strictly named "${fileName}.data" next to the .onnx file.
        if (!file.exists() || !dataFile.exists()) {
            Log.d("Antigravity-SD", "Copying model & data: $fileName...")
            
            // 1. Copy .onnx
            copyAssetToFile("models/sd/$fileName", overwrite = true)
            
            // 2. Copy .data (Catch exception if not present, but for unet_static_fp16 it IS required)
            try {
                copyAssetToFile("models/sd/$fileName.data", overwrite = true)
            } catch (e: Exception) {
                if (fileName.contains("static")) {
                   Log.e("Antigravity-SD", "CRITICAL: .data file missing for $fileName!", e)
                   throw e // Fail hard for static model
                } else {
                   Log.w("Antigravity-SD", "No .data file found for $fileName (might be single file model).")
                }
            }
        }
        return file.absolutePath
    }

    private fun copyAssetToFile(assetPath: String, overwrite: Boolean = false) {
        val destFilename = java.io.File(assetPath).name
        val file = java.io.File(context.filesDir, destFilename)
        
        if (!overwrite && file.exists() && file.length() > 0) {
            Log.d("Antigravity-SD", "$destFilename already exists (${file.length()} bytes). Skipping copy.")
            return
        }
        
        Log.d("Antigravity-SD", "Installing $assetPath as $destFilename (Overwrite: $overwrite)...")
        try {
            context.assets.open(assetPath).use { input ->
                java.io.FileOutputStream(file).use { output ->
                    input.copyTo(output)
                }
            }
            Log.d("Antigravity-SD", "Installed $destFilename (${file.length()} bytes).")
        } catch (e: Exception) {
            Log.e("Antigravity-SD", "Failed to copy $assetPath", e)
            throw e
        }
    }

    fun generateImage(prompt: String): Flow<GenerationStatus> = flow {
        val startTime = System.currentTimeMillis()

        // ğŸ› ï¸ ìˆ˜ì •: ì—ëŸ¬ ë‚˜ë˜ providers í™•ì¸ ì½”ë“œ ì‚­ì œ
        // ëŒ€ì‹  ë¡œê·¸ì™€ í™”ë©´ì— "Batch 1 ì „ëµ ì ìš©ë¨"ì„ ëª…ì‹œ
        val debugMsg = "Strategy: Batch 1 (Split)\nEngine: NPU (Target)"

        Log.d("Antigravity-SD", "STARTING GENERATION: $debugMsg")
        emit(GenerationStatus.Started(debugMsg))
        emit(GenerationStatus.InProgress(0, "Encoding Text..."))

        // 1. Text Embeddings (Batch 1ì„ ìœ„í•´ ë¶„ë¦¬)
        val tokenIds = tokenizer.tokenize(prompt)
        val condEmbeddings = encodeText(tokenIds)
        val uncondEmbeddings = encodeText(IntArray(77) { 49407 })

        // ğŸš¨ FP16 Conversion handled inside runUNet now, so pass FloatBuffers
        val condBuffer = FloatBuffer.wrap(condEmbeddings)
        val uncondBuffer = FloatBuffer.wrap(uncondEmbeddings)

        // 2. Scheduler Setup
        val timesteps = getTimesteps(numInferenceSteps)
        val initSigma = sigmas[timesteps[0].toInt()]
        var latents = generateRandomLatents(1, 4, 64, 64) // 1ê°œì§œë¦¬ Latent

        for (i in latents.indices) {
            latents[i] = latents[i] * sqrt(initSigma.pow(2) + 1)
        }

        emit(GenerationStatus.InProgress(10, "Running NPU (Batch 1)..."))

        val chunkSize = 4 * 64 * 64
        val latentInput = FloatArray(chunkSize)
        val latentInputBuffer = FloatBuffer.wrap(latentInput) // Reuse FloatBuffer wrapper
        val guidance = 7.5f

        // 4. Denoising Loop (ì†ë„ì˜ í•µì‹¬)
        for ((index, t) in timesteps.withIndex()) {
            val stepStart = System.nanoTime()
            val sigma = sigmas[t.toInt()]

            val scale = 1.0f / sqrt(sigma.pow(2) + 1)
            for (i in 0 until chunkSize) {
                latentInput[i] = latents[i] * scale
            }

            // âš¡âš¡ [STEP 1] Negative í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ (Batch 1)
            latentInputBuffer.rewind() // Ensuring position 0
            uncondBuffer.rewind() // Ensuring position 0
            val noiseUncond = runUNet(latentInputBuffer, t, uncondBuffer)

            // âš¡âš¡ [STEP 2] Positive í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ (Batch 1)
            latentInputBuffer.rewind()
            condBuffer.rewind() // Ensuring position 0
            val noiseCond = runUNet(latentInputBuffer, t, condBuffer)

            // [STEP 3] ê²°ê³¼ í•©ì¹˜ê¸° (CFG)
            // noise = uncond + guidance * (cond - uncond)
            val sigmaTo = if (index + 1 < timesteps.size) sigmas[timesteps[index+1].toInt()] else 0.0f
            val sigmaUp = sqrt((sigmaTo.pow(2) * (sigma.pow(2) - sigmaTo.pow(2))) / sigma.pow(2))
            val sigmaDown = sqrt(sigmaTo.pow(2) - sigmaUp.pow(2))
            val dt = sigmaDown - sigma
            val rand = java.util.Random()

            for (i in 0 until chunkSize) {
                val nU = noiseUncond[i]
                val nC = noiseCond[i]
                val noise = nU + guidance * (nC - nU)

                latents[i] += noise * dt
                if (sigmaTo > 0.0f) {
                    latents[i] += rand.nextGaussian().toFloat() * sigmaUp
                }
            }

            val stepTotalTime = (System.nanoTime() - stepStart) / 1_000_000.0
            val progress = 10 + ((index + 1).toFloat() / numInferenceSteps * 80).roundToInt()

            // ì†ë„ ë¡œê·¸ ì°ê¸°
            Log.d("Antigravity-SD", "Step ${index+1}: ${String.format("%.0f", stepTotalTime)}ms")
            emit(GenerationStatus.InProgress(progress, "Step ${index + 1} (${String.format("%.0f", stepTotalTime)}ms)"))
        }

        emit(GenerationStatus.InProgress(95, "Decoding..."))
        val image = runVAEDecoder(latents)
        val endTime = System.currentTimeMillis()
        emit(GenerationStatus.Success(image, endTime - startTime))
    }.flowOn(Dispatchers.Default)

    private fun getTimesteps(steps: Int): IntArray {
        // Linear spacing 999 -> 0
        val ts = IntArray(steps)
        val stepSize = 1000 / steps
        for (i in 0 until steps) {
            ts[i] = 999 - (i * stepSize)
        }
        return ts
    }

    private suspend fun encodeText(tokenIds: IntArray): FloatArray {
        if (textEncoderSession == null) return FloatArray(77 * 768) // Mock
        return withContext(Dispatchers.Default) {
            val inputTensor = OnnxTensor.createTensor(env, IntBuffer.wrap(tokenIds), longArrayOf(1, 77))
            val result = textEncoderSession!!.run(mapOf("input_ids" to inputTensor))
            val output = result[0] as OnnxTensor
            val floatBuffer = output.floatBuffer
            val out = FloatArray(floatBuffer.remaining())
            floatBuffer.get(out)
            result.close()
            out
        }
    }

    private fun toFP16Buffer(floats: FloatBuffer): ByteBuffer {
        val buffer = ByteBuffer.allocateDirect(floats.remaining() * 2)
        buffer.order(ByteOrder.nativeOrder())
        fillFP16Buffer(floats, buffer)
        return buffer
    }

    private fun fillFP16Buffer(floats: FloatBuffer, dest: ByteBuffer) {
        dest.clear()
        floats.rewind() // Ensuring we read from start (assuming full buffer use)
        while (floats.hasRemaining()) {
            dest.putShort(Half.toHalf(floats.get()))
        }
        dest.flip() // Prepare for reading
        floats.rewind()
    }

    // [ë³´ì¡° í•¨ìˆ˜] FP16 ByteBufferë¥¼ FloatArrayë¡œ ë³€í™˜
    private fun fromFP16ToFloatArray(buffer: ByteBuffer): FloatArray {
        // Create a ShortBuffer view
        val shorts = buffer.order(ByteOrder.nativeOrder()).asShortBuffer()
        val floats = FloatArray(shorts.remaining())
        for (i in floats.indices) {
            floats[i] = Half.toFloat(shorts.get(i))
        }
        return floats
    }

    private suspend fun runUNet(sample: FloatBuffer, timestep: Int, encoderHiddenStates: FloatBuffer): FloatArray {
        if (unetSession == null) return FloatArray(1 * 4 * 64 * 64)

        return withContext(Dispatchers.Default) {
            var sampleTensor: OnnxTensor? = null
            var tTensor: OnnxTensor? = null
            var encoderTensor: OnnxTensor? = null
            var result: OrtSession.Result? = null

            try {
                // 1. Input ì¤€ë¹„ (ëª¨ë‘ FP16ìœ¼ë¡œ ë³€í™˜!)
                // ORT Cast ì‚½ì… ë°©ì§€ë¥¼ ìœ„í•´ Explicit FP16 Type ì‚¬ìš© í•„ìˆ˜
                val sampleFP16 = toFP16Buffer(sample)
                val encoderFP16 = toFP16Buffer(encoderHiddenStates)
                val tBuffer = FloatBuffer.wrap(floatArrayOf(timestep.toFloat()))
                val tFP16 = toFP16Buffer(tBuffer)

                // 2. í…ì„œ ìƒì„± (Explicit FP16 Type) - BATCH 1 ENFORCED
                sampleTensor = OnnxTensor.createTensor(env, sampleFP16, longArrayOf(1, 4, 64, 64), OnnxJavaType.FLOAT16)
                tTensor = OnnxTensor.createTensor(env, tFP16, longArrayOf(1), OnnxJavaType.FLOAT16)
                encoderTensor = OnnxTensor.createTensor(env, encoderFP16, longArrayOf(1, 77, 768), OnnxJavaType.FLOAT16)

                val inputs = mapOf(
                    "sample" to sampleTensor,
                    "timestep" to tTensor,
                    "encoder_hidden_states" to encoderTensor
                )

                // 3. ì‹¤í–‰ (Inference)
                // ì´ì œ 'Cast' ë…¸ë“œ ì—†ì´ NPUë¡œ ì§í–‰í•©ë‹ˆë‹¤.
                result = unetSession!!.run(inputs)

                // 4. ì¶œë ¥ ì²˜ë¦¬
                val outputTensor = result!!.get(0) as OnnxTensor

                // ì¶œë ¥ì´ FP16ìœ¼ë¡œ ë‚˜ì˜¤ë©´ ë³€í™˜, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                if (outputTensor.info.type == OnnxJavaType.FLOAT16) {
                    fromFP16ToFloatArray(outputTensor.byteBuffer)
                } else {
                    val fb = outputTensor.floatBuffer
                    val out = FloatArray(fb.remaining())
                    fb.get(out)
                    out
                }

            } finally {
                sampleTensor?.close()
                tTensor?.close()
                encoderTensor?.close()
                result?.close()
            }
        }
    }

    private suspend fun runVAEDecoder(latents: FloatArray): Bitmap {
        if (vaeDecoderSession == null) return createNoiseBitmap(512, 512)
        return withContext(Dispatchers.Default) {
            // Latents ìŠ¤ì¼€ì¼ë§
            val scaledLatents = FloatArray(latents.size) { i -> latents[i] / 0.18215f }

            // ğŸš¨ [ìˆ˜ì • í¬ì¸íŠ¸] VAE ì…ë ¥ë„ FP16ìœ¼ë¡œ ë³€í™˜!
            val latentsBuffer = FloatBuffer.wrap(scaledLatents)
            val latentsFP16 = toFP16Buffer(latentsBuffer)
            
            var inputTensor: OnnxTensor? = null
            var result: OrtSession.Result? = null

            try {
                // í…ì„œ ìƒì„± (FP16)
                inputTensor = OnnxTensor.createTensor(env, latentsFP16, longArrayOf(1, 4, 64, 64), OnnxJavaType.FLOAT16)

                // ì‹¤í–‰
                result = vaeDecoderSession!!.run(mapOf("latent_sample" to inputTensor))

                val output = result!!.get(0) as OnnxTensor
                val fb = output.floatBuffer // VAE Output is usually FP32
                
                // Convert NCHW [1, 3, 512, 512] to ARGB
                val width = 512
                val height = 512
                val colors = IntArray(width * height)
                
                // Plane offsets for NCHW layout
                val rOffset = 0
                val gOffset = width * height
                val bOffset = 2 * width * height
                
                for (y in 0 until height) {
                    for (x in 0 until width) {
                        val i = y * width + x
                        
                        val rVal = fb[rOffset + i]
                        val gVal = fb[gOffset + i]
                        val bVal = fb[bOffset + i]
                        
                        // Helper strict denormalization: (val + 1) * 127.5
                        val r = ((rVal + 1.0f) * 127.5f).coerceIn(0f, 255f).toInt()
                        val g = ((gVal + 1.0f) * 127.5f).coerceIn(0f, 255f).toInt()
                        val b = ((bVal + 1.0f) * 127.5f).coerceIn(0f, 255f).toInt()
                        
                        // Alpha is always 255 (0xFF)
                        colors[i] = (0xFF shl 24) or (r shl 16) or (g shl 8) or b
                    }
                }
                
                Bitmap.createBitmap(colors, width, height, Bitmap.Config.ARGB_8888)
            } finally {
                 result?.close()
                 inputTensor?.close()
            }
        }
    }
    
    private fun generateRandomLatents(b: Int, c: Int, h: Int, w: Int): FloatArray {
         val rand = java.util.Random()
         return FloatArray(b * c * h * w) { rand.nextGaussian().toFloat() }
    }
    
    // ... [Status classes and Mock Bitmap Helper] ...
    private fun createNoiseBitmap(w: Int, h: Int): Bitmap {
        val conf = Bitmap.Config.ARGB_8888
        val bmp = Bitmap.createBitmap(w, h, conf)
        for(x in 0 until w step 10) {
            for (y in 0 until h step 10) {
                 bmp.setPixel(x, y, Color.rgb((0..255).random(), (0..255).random(), (0..255).random()))
            }
        }
        return bmp
    }

    sealed class GenerationStatus {
        data class InProgress(val progress: Int, val message: String) : GenerationStatus()
        data class Started(val config: String) : GenerationStatus()
        class Success(val image: Bitmap, val timeMs: Long) : GenerationStatus()
        class Error(val exception: Throwable) : GenerationStatus()
    }
}
